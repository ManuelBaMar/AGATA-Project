{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a5971c1-c8b7-4973-8366-a5b2f4cd374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importamos las librerias necesarias:\n",
    "##Importamos Pandas para trabajar con DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "##Importamos Numpy para incluir mas funciones matematicas\n",
    "import numpy as np\n",
    "\n",
    "##Importamos MatPlotLib para realizar representaciones\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec #Es un paquete de matplotlib que permite realizar figuras de varias subfiguras\n",
    "\n",
    "##Importamos la funcion display de la libreria IPython.display, que permite mostrar contenido de manera mas enriquecida\n",
    "from IPython.display import display\n",
    "\n",
    "##Importamos el modulo time para poder medir el tiempo de ejecución del codigo\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33b703e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Definimos la funcion para leer el archivo completo\n",
    "def read_MBS_data_full(path):\n",
    "    ##Cargamos los datos en un data frame\n",
    "    inputfile = pd.read_csv(path, sep = \"\\t\", header = None, dtype = np.float64, chunksize = None) #Tabulaciones como separador, sin encabezado y sin realizar division del dataframe\n",
    "    df = inputfile.drop([1, 2, 3, 4, 129, 130], axis = 1, errors = 'ignore') #Elimino las columnas asociadas a las coordenadas y las dos ultimas que son 0 y Nan\n",
    "\n",
    "    #Cambio las etiquetas de las columnas para que coincidan con el tiempo y el canal correspondiente\n",
    "    etiquetas = [\"tiempo\"] + list(range(1, 125))\n",
    "    df.columns = etiquetas\n",
    "\n",
    "    return df #Devuelve un data frame\n",
    "    \n",
    "\n",
    "##Definimos la funcion para leer el archivo en chunks\n",
    "def read_MBS_data_in_chunks(path, chunksize = 10000):\n",
    "    ##Generamos el objeto iterable de los datos\n",
    "    inputfile = pd.read_csv(path, sep = \"\\t\", header = None, dtype = np.float64, chunksize = int(chunksize)) #Tabulaciones como separador, sin encabezado, con division del dataframe\n",
    "    #Defino las etiquetas\n",
    "    etiquetas = [\"tiempo\"] + list(range(1, 125))\n",
    "    #Itero sobre el objeto iterable generado para realizr modeificaciones a cada chunk\n",
    "    for chunk in inputfile:\n",
    "        chunk.drop([1, 2, 3, 4, 129, 130], axis = 1, inplace = True, errors = 'ignore') #Elimino las columnas seleccionadas, reemplalzando el archivo en lugar de generar uno nuevo\n",
    "        chunk.columns = etiquetas #Cambio las etiquetas del dataframe en cada chunk\n",
    "\n",
    "        #Al emplear la sentencia yield estamos convirtiendo la funcion en una funcion generadora, proporcionando un objeto iterable como resultado\n",
    "        yield chunk #Sustituye al return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e54207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Funcion para detectar la presencia de eventos en cada observacion\n",
    "def detect_events(row):\n",
    "    #Implementacion del algoritmo de deteccion de eventos para cada fila\n",
    "    #Inicializamos los marcadores\n",
    "    flag1 = 0\n",
    "    flag2 = 0\n",
    "    flag3 = 0\n",
    "    time = row[\"tiempo\"]\n",
    "    col_counter = 1\n",
    "\n",
    "    #Empezamos a iterar sobre los elementos de la fila \n",
    "    for column in row[1:]: \n",
    "        if (column < 10000) and (flag1 == 0): #Comprobamos si se produce una caida en la señal. Si se cumple se marca flag1\n",
    "            flag1 = 1\n",
    "            time_coincidence = col_counter\n",
    "        \n",
    "        if (column > 20000) and (flag1 == 1): #Comprobamos si se produce una subida en la señal despues de haberse producido una caida, lo que indica evento. Si se cumple se marca flag2\n",
    "            flag2 = 1\n",
    "        \n",
    "        if (column < 15000) and (flag2 == 1): #Si habiendose producido una coincidencia (flag2 = 1) se produce otra, se marca para descartar el evento (flag3 = 1) y se resetean los marcadores\n",
    "            flag3 = 1\n",
    "            flag2 = 0\n",
    "            flag1 = 0\n",
    "        else: \n",
    "            col_counter += 1\n",
    "            continue\n",
    "\n",
    "    #Se comprueban los marcadores para saber si se ha dado una coincidencia aislada\n",
    "    #Se devvuelve si se produce coincidencia y el tiempo en el que se produce\n",
    "    if (time != 0) and (flag1 == 1) and (flag2 == 1) and (flag3 != 1): #Si se ha detectado solo un evento aislado se devuelve 1 (Se comprueba tambien que el tiempo no sea 0, lo cual no seria valido)\n",
    "        return {'Coincidencia': 1, 'Time_event': time + time_coincidence - 1}\n",
    "    else:   #Si no se ha detectado evento o si se ha producido una coincidencia multiple se devuelve 0 \n",
    "        return {'Coincidencia': 0, 'Time_event': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25b288e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Función para el proceso de obtencion de las coincidencias en caso de cargar el archivo de datos original al completo\n",
    "def data_procesing_full(path):\n",
    "    #Leemos el DataFrame con una de las funciones definidas (cargamos el archivo al completo)\n",
    "    df = read_MBS_data_full(path)\n",
    "\n",
    "    ##Detectamos las coincidencias\n",
    "    df[[\"Coincidencia\", \"Time_event\"]] = df.apply(detect_events, axis = 1, result_type='expand') #La funcion devuelve si hay coincidencia y el tiempo en el que se produce (como devuelve un diccionario con dos keys se emplea el argumento result_type='expand', para descomprimir el resultado)\n",
    "    df[\"Num_event\"] = df.index + 1 #Definimos el número de evento. Más 1 para que el número de evento empiece en 1 y no en 0\n",
    "    print(df.value_counts(\"Coincidencia\")) #Recuento de coincidencias\n",
    "    #Guardo el DataFrame que emplearé para entrenar la Neural Network (NN)\n",
    "    df.to_csv(\"./Data/NN_coincidencias_data.dat\", index = True, sep = \"\\t\")\n",
    "\n",
    "    ##Genero un nuevo DataFrame filtrando las observaciones que producen coincidencias\n",
    "    df_coincidencias = df[df[\"Coincidencia\"] == 1]\n",
    "    df_coincidencias.index = range(1, len(df_coincidencias) + 1) #Cambio el indice para que empiece en 1\n",
    "\n",
    "    #En un nuevo dataframe guardo el índice, el número de coincidencia y el tiempo de la coincidencia\n",
    "    final_df = df_coincidencias[[\"Num_event\", \"Time_event\"]].copy()\n",
    "    #Genero el archivo de texto con los resultados del muestreo\n",
    "    final_df.to_csv(\"./Data/Coincidencias_MBS.dat\", index = True, sep = \"\\t\")\n",
    "\n",
    "\n",
    "###Función para el proceso de obtencion de las coincidencias en caso de cargar el archivo de datos original por partes para no sobrecargar la memoria\n",
    "def data_procesing_in_chunks(path):\n",
    "    #Leemos el archivo de datos por partes \n",
    "    df_in_chunks = read_MBS_data_in_chunks(path, chunksize = 100)\n",
    "\n",
    "    #Creo los archivos sobre los que se van a escribir los resultados, definiendo unicamente el encabezado\n",
    "    df_NN_vacio = pd.DataFrame(columns = [\"tiempo\"] + list(range(1,125)) + [\"Coincidencia\", \"Time_event\", \"Num_event\"]) #Encabezado del DataFrame para la NN\n",
    "    df_coincidencias_vacio = pd.DataFrame(columns = [\"Num_event\", \"Time_event\"]) #Encabezado del archivo de coincidencias\n",
    "    df_NN_vacio.to_csv(\"./Data/NN_coincidencias_data.dat\", index = True, sep = \"\\t\", header = True, mode = \"w\") #Creacion del archivo de NN\n",
    "    df_coincidencias_vacio.to_csv(\"./Data/Coincidencias_MBS.dat\", index = True, sep = \"\\t\", header = True, mode = \"w\") #Creacion del archivo de coincidencias\n",
    "\n",
    "\n",
    "    ##Iteramos sobre cada parte del archivo para trabajar con los diferentes segmentos\n",
    "    count = 0 #Variable para llevar el recuento de las coincidencias en cada chunk\n",
    "\n",
    "    for chunk in df_in_chunks:\n",
    "        #Detectamos las coincidencias\n",
    "        chunk[[\"Coincidencia\", \"Time_event\"]] = chunk.apply(detect_events, axis = 1, result_type='expand')\n",
    "        chunk[\"Num_event\"] = chunk.index + 1 #Definimos el número de evento. Más 1 para que el número de evento empiece en 1 y no en 0\n",
    "        #Vamos guardando la parte correspondiente a cada chunk en el mismo archivo que se usara para entrenar la NN\n",
    "        chunk.to_csv(\"./Data/NN_coincidencias_data.dat\", index = True, sep = \"\\t\", header = False, mode = \"a\")\n",
    "\n",
    "        ##Genero un nuevo DataFrame filtrando las observaciones que producen coincidencias\n",
    "        chunk_coincidencias = chunk[chunk[\"Coincidencia\"] == 1]\n",
    "        chunk_coincidencias.index = range(1 + count, count + len(chunk_coincidencias) + 1) #Cambio el indice para que empiece en 1\n",
    "        count = count + len(chunk_coincidencias)\n",
    "\n",
    "        #En un nuevo dataframe guardo el índice, el número de coincidencia y el tiempo de la coincidencia\n",
    "        final_chunk = chunk_coincidencias[[\"Num_event\", \"Time_event\"]].copy()\n",
    "        #Genero el archivo de texto con los resultados del muestreo\n",
    "        final_chunk.to_csv(\"./Data/Coincidencias_MBS.dat\", index = True, sep = \"\\t\", header = False, mode = \"a\")\n",
    "\n",
    "    print(\"El número de coincidencias totales detectadas es: {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6380bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de coincidencias totales detectadas es: 138\n",
      "El tiempo de ejecucion del codigo ha sido: 0.1058359146118164 segundos\n"
     ]
    }
   ],
   "source": [
    "##Se pregunta si la caga de datos se quiere hacer de manera segmentada o a la vez\n",
    "decision = input(\"Introduce si quieres leer el archivo de datos cargandolo a la vez o de manera segmentada: True (carga segmentada), False (carga a la vez)\")\n",
    "\n",
    "##Inicio del contador de tiempos\n",
    "start = time.time()\n",
    "\n",
    "##Ruta al archivo de datos\n",
    "MBS_data = \"./Data/MBS_data.dat\"\n",
    "\n",
    "##Ejecutamos el bloque de comandos asociado a la carga simultanea o segmentada dependiendo de la decision introducida\n",
    "if decision == \"False\":\n",
    "    data_procesing_full(MBS_data)\n",
    "\n",
    "if decision == \"True\":\n",
    "    data_procesing_in_chunks(MBS_data)\n",
    "\n",
    "##Fin del contador de tiempos\n",
    "end = time.time()\n",
    "#Tiempos transcurrido\n",
    "execution_time = end - start\n",
    "print(\"El tiempo de ejecucion del codigo ha sido: {} segundos\".format(execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
